[09:59:15] /home/t-leiwang/mlc_workspace/unity/src/tir/transforms/split_host_device.cc:143: updates when create # from tvm.script import ir as I

@I.ir_module
class Module:
    pass
[09:59:15] /home/t-leiwang/mlc_workspace/unity/src/tir/transforms/split_host_device.cc:165: updates # from tvm.script import ir as I

@I.ir_module
class Module:
    pass
[09:59:15] /home/t-leiwang/mlc_workspace/unity/src/tir/transforms/split_host_device.cc:143: updates when create # from tvm.script import ir as I

@I.ir_module
class Module:
    pass
[09:59:15] /home/t-leiwang/mlc_workspace/unity/src/tir/transforms/split_host_device.cc:158: pdates->Add I.GlobalVar("main") # from tvm.script import tir as T

@T.prim_func
def main(a: T.handle, B: T.Buffer((1024, 1024), "float16"), c: T.handle):
    T.func_attr({"dlight.tensorcore_prenormlized": T.bool(True), "opt_shapes": {"m": 1024}, "target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.noalias": T.bool(True)})
    m = T.int32()
    A = T.match_buffer(a, (m, 1024), "float16")
    C = T.match_buffer(c, (m, 1024), "float16")
    # with T.block("root"):
    A_reindex_pad_shared = T.alloc_buffer((1, (m + 63) // 64 * 64, 1024), "float16", scope="shared")
    B_reindex_shared = T.alloc_buffer((1, 1024, 1024), "float16", scope="shared")
    A_reindex_pad_shared_warp = T.alloc_buffer((1, (m + 63) // 64 * 4, 64, 32, 8), "float16", scope="warp")
    B_reindex_shared_warp = T.alloc_buffer((1, 64, 64, 32, 8), "float16", scope="warp")
    C_reindex_pad_shared = T.alloc_buffer((1, (m + 63) // 64 * 4, 64, 16, 16), "float16", scope="shared")
    C_reindex_pad_shared_warp = T.alloc_buffer((1, (m + 63) // 64 * 4, 64, 32, 8), "float16", scope="warp")
    A_1 = T.handle("float16", "warp")
    B_1 = T.handle("float16", "warp")
    C_1 = T.handle("float16", "warp")
    C_1_1 = T.handle("float16", "shared")
    C_warp = T.handle("float16", "warp")
    C_warp_1 = T.handle("float16", "warp")
    shared = T.handle("float16", "shared")
    shared_1 = T.handle("float16", "shared")
    warp = T.handle("float16", "warp")
    warp_1 = T.handle("float16", "warp")
    C_1_s0 = T.int32()
    elem_offset = T.int32()
    elem_offset_1 = T.int32()
    elem_offset_2 = T.int32()
    elem_offset_3 = T.int32()
    elem_offset_4 = T.int32()
    elem_offset_5 = T.int32()
    elem_offset_6 = T.int32()
    elem_offset_7 = T.int32()
    elem_offset_8 = T.int32()
    elem_offset_9 = T.int32()
    shared_s0 = T.int32()
    shared_s0_1 = T.int32()
    v0 = T.int32()
    v0_1 = T.int32()
    v0_2 = T.int32()
    v0_o = T.int32()
    v0_o_1 = T.int32()
    v0_o_2 = T.int32()
    v1 = T.int32()
    v1_1 = T.int32()
    v1_2 = T.int32()
    v1_o = T.int32()
    v1_o_1 = T.int32()
    v1_o_2 = T.int32()
    v1_o_3 = T.int32()
    v1_o_4 = T.int32()
    v2 = T.int32()
    v2_1 = T.int32()
    v2_2 = T.int32()
    v2_o = T.int32()
    v2_o_1 = T.int32()
    v2_o_2 = T.int32()
    v2_o_3 = T.int32()
    v2_o_4 = T.int32()
    v3 = T.int32()
    v3_o = T.int32()
    v4 = T.int32()
    main_kernel(A.data, A_1, A_reindex_pad_shared.data, B.data, B_1, B_reindex_shared.data, C.data, C_1, C_1_1, C_reindex_pad_shared.data, C_warp, C_warp_1, shared, shared_1, warp, warp_1, C_1_s0, elem_offset, elem_offset_1, elem_offset_2, elem_offset_3, elem_offset_4, elem_offset_5, elem_offset_6, elem_offset_7, elem_offset_8, elem_offset_9, m, shared_s0, shared_s0_1, v0, v0_1, v0_2, v0_o, v0_o_1, v0_o_2, v1, v1_1, v1_2, v1_o, v1_o_1, v1_o_2, v1_o_3, v1_o_4, v2, v2_1, v2_2, v2_o, v2_o_1, v2_o_2, v2_o_3, v2_o_4, v3, v3_o, v4)
[09:59:15] /home/t-leiwang/mlc_workspace/unity/src/tir/transforms/split_host_device.cc:165: updates # from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(a: T.handle, B: T.Buffer((1024, 1024), "float16"), c: T.handle):
        T.func_attr({"dlight.tensorcore_prenormlized": T.bool(True), "opt_shapes": {"m": 1024}, "target": T.target({"arch": "sm_80", "keys": ["cuda", "gpu"], "kind": "cuda", "max_num_threads": 1024, "tag": "", "thread_warp_size": 32}), "tir.is_global_func": T.bool(True), "tir.noalias": T.bool(True)})
        m = T.int32()
        A = T.match_buffer(a, (m, 1024), "float16")
        C = T.match_buffer(c, (m, 1024), "float16")
        # with T.block("root"):
        A_reindex_pad_shared = T.alloc_buffer((1, (m + 63) // 64 * 64, 1024), "float16", scope="shared")
        B_reindex_shared = T.alloc_buffer((1, 1024, 1024), "float16", scope="shared")
        A_reindex_pad_shared_warp = T.alloc_buffer((1, (m + 63) // 64 * 4, 64, 32, 8), "float16", scope="warp")
        B_reindex_shared_warp = T.alloc_buffer((1, 64, 64, 32, 8), "float16", scope="warp")
        C_reindex_pad_shared = T.alloc_buffer((1, (m + 63) // 64 * 4, 64, 16, 16), "float16", scope="shared")
        C_reindex_pad_shared_warp = T.alloc_buffer((1, (m + 63) // 64 * 4, 64, 32, 8), "float16", scope="warp")
        A_1 = T.handle("float16", "warp")
        B_1 = T.handle("float16", "warp")
        C_1 = T.handle("float16", "warp")
        C_1_1 = T.handle("float16", "shared")
        C_warp = T.handle("float16", "warp")
        C_warp_1 = T.handle("float16", "warp")
        shared = T.handle("float16", "shared")
        shared_1 = T.handle("float16", "shared")
        warp = T.handle("float16", "warp")
        warp_1 = T.handle("float16", "warp")
        C_1_s0 = T.int32()
        elem_offset = T.int32()
        elem_offset_1 = T.int32()
        elem_offset_2 = T.int32()
        elem_offset_3 = T.int32()
        elem_offset_4 = T.int32()
        elem_offset_5 = T.int32()
        elem_offset_6 = T.int32()
        elem_offset_7 = T.int32()
        elem_offset_8 = T.int32()
        elem_offset_9 = T.int32()
        shared_s0 = T.int32()
        shared_s0_1 = T.int32()
        v0 = T.int32()
        v0_1 = T.int32()
        v0_2 = T.int32()
        v0_o = T.int32()
        v0_o_1 = T.int32()
        v0_o_2 = T.int32()
        v1 = T.int32()
        v1_1 = T.int32()
        v1_2 = T.int32()
        v1_o = T.int32()
        v1_o_1 = T.int32()
        v1_o_2 = T.int32()
        v1_o_3 = T.int32()
        v1_o_4 = T.int32()
        v2 = T.int32()
        v2_1 = T.int32()
        v2_2 = T.int32()
        v2_o = T.int32()
        v2_o_1 = T.int32()
        v2_o_2 = T.int32()
        v2_o_3 = T.int32()
        v2_o_4 = T.int32()
        v3 = T.int32()
        v3_o = T.int32()
        v4 = T.int32()
        main_kernel(A.data, A_1, A_reindex_pad_shared.data, B.data, B_1, B_reindex_shared.data, C.data, C_1, C_1_1, C_reindex_pad_shared.data, C_warp, C_warp_1, shared, shared_1, warp, warp_1, C_1_s0, elem_offset, elem_offset_1, elem_offset_2, elem_offset_3, elem_offset_4, elem_offset_5, elem_offset_6, elem_offset_7, elem_offset_8, elem_offset_9, m, shared_s0, shared_s0_1, v0, v0_1, v0_2, v0_o, v0_o_1, v0_o_2, v1, v1_1, v1_2, v1_o, v1_o_1, v1_o_2, v1_o_3, v1_o_4, v2, v2_1, v2_2, v2_o, v2_o_1, v2_o_2, v2_o_3, v2_o_4, v3, v3_o, v4)
